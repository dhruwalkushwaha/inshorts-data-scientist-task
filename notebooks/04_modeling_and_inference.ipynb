{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "689zuusX7lBo"
      },
      "outputs": [],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 04_modeling_and_inference.ipynb  \\n\",\n",
        "    \"---\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Step 1: Loading & Preparing Data  \\n\",\n",
        "    \"*We’re loading the saved CSVs for users, content, and training labels, then converting date strings into numeric timestamps for modeling.*\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Loading user features to merge aggregated user signals\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"user_df = pd.read_csv('user_features.csv')  \\n\",\n",
        "    \"# Loading content features to merge aggregated content signals\\n\",\n",
        "    \"content_df = pd.read_csv('content_features.csv')  \\n\",\n",
        "    \"# Loading combined training data (positive interactions + negative candidates)\\n\",\n",
        "    \"train_df = pd.read_csv('training_data.csv')  \\n\",\n",
        "    \"# Parsing datetime columns into Unix timestamps\\n\",\n",
        "    \"for col in ['first_seen', 'last_seen']:\\n\",\n",
        "    \"    train_df[col] = (pd.to_datetime(train_df[col], errors='coerce')  \\n\",\n",
        "    \"                        .astype('int64') // 10**9)\\n\",\n",
        "    \"# Quick sanity check shapes\\n\",\n",
        "    \"print(f\\\"User: {user_df.shape}, Content: {content_df.shape}, Train: {train_df.shape}\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Step 2: Feature Matrix Construction  \\n\",\n",
        "    \"*We’re merging user & content features into a single DataFrame, then splitting into X (features) and y (labels).*\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Merge user-level signals\\n\",\n",
        "    \"train = train_df.merge(user_df, on='deviceId', how='left')  \\n\",\n",
        "    \"# Merge content-level signals\\n\",\n",
        "    \"train = train.merge(content_df, on='hashId', how='left')  \\n\",\n",
        "    \"# Save for reproducibility\\n\",\n",
        "    \"train.to_csv('train.csv', index=False)  \\n\",\n",
        "    \"# Prepare feature matrix and target\\n\",\n",
        "    \"X = train.drop(columns=['deviceId','hashId','label']).select_dtypes(include=['int64','float64'])  \\n\",\n",
        "    \"y = train['label']  \\n\",\n",
        "    \"print(f\\\"X shape: {X.shape}, positive rate: {y.mean():.4f}\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Step 3: Model Training & Validation  \\n\",\n",
        "    \"*We’re splitting the data, training a LightGBM classifier with early stopping, and evaluating via AUC.*\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"from sklearn.metrics import roc_auc_score\\n\",\n",
        "    \"import lightgbm as lgb\\n\",\n",
        "    \"from lightgbm import LGBMClassifier\\n\",\n",
        "    \"# Split\\n\",\n",
        "    \"X_train,X_val,y_train,y_val = train_test_split(X,y,stratify=y,test_size=0.2,random_state=42)\\n\",\n",
        "    \"# Train\\n\",\n",
        "    \"model = LGBMClassifier(n_estimators=200,random_state=42)\\n\",\n",
        "    \"model.fit(\\n\",\n",
        "    \"    X_train, y_train,\\n\",\n",
        "    \"    eval_set=[(X_val,y_val)],\\n\",\n",
        "    \"    callbacks=[lgb.early_stopping(20)]\\n\",\n",
        "    \")\\n\",\n",
        "    \"# Evaluate\\n\",\n",
        "    \"preds = model.predict_proba(X_val)[:,1]\\n\",\n",
        "    \"print('Validation AUC:', roc_auc_score(y_val,preds))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Step 4: Prediction & Submission  \\n\",\n",
        "    \"*We’re loading test candidates, merging features, scoring, and exporting top-50 per user.*\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"test_candidates = pd.read_csv('test_candidates.csv')  \\n\",\n",
        "    \"X_test = test_candidates.merge(user_df,on='deviceId',how='left')\\n\",\n",
        "    \"X_test = X_test.merge(content_df,on='hashId',how='left')\\n\",\n",
        "    \"for col in ['first_seen','last_seen']:\\n\",\n",
        "    \"    X_test[col] = pd.to_datetime(X_test[col],errors='coerce').astype('int64')//1e9\\n\",\n",
        "    \"X_test_model = X_test[X.columns]  \\n\",\n",
        "    \"test_candidates['label'] = model.predict_proba(X_test_model)[:,1]  \\n\",\n",
        "    \"test_candidates.to_csv('submission.csv',index=False)  \\n\",\n",
        "    \"test_candidates.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"*End of notebook. Everything cleaned up and ready for review.*\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"name\": \"python\",\n",
        "   \"version\": \"3.11\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 5\n",
        "}\n"
      ]
    }
  ]
}