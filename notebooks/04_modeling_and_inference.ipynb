{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Loading & Preparing Data\n",
        "\n",
        "*Weâ€™re loading the saved CSVs for users, content, and training labels, then converting date strings into numeric timestamps for modeling.*\n"
      ],
      "metadata": {
        "id": "Nn3Rj92wfM0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic utilities\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import glob\n",
        "\n"
      ],
      "metadata": {
        "id": "BL0t69MOlryX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive mounting & project path setup\n",
        "from google.colab import drive\n",
        "import os, zipfile\n",
        "\n",
        "# Step 1: Mounting Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Defining paths\n",
        "zip_path = '/content/drive/MyDrive/test_data (1).zip'\n",
        "base_path = '/content/drive/MyDrive/projects/news-recommendation-systems'\n",
        "extract_path = os.path.join(base_path, 'test_data')  # where your real files are\n",
        "\n",
        "# Step 3: Unzipping if not already extracted\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(base_path)\n",
        "        print(\" Extracted zip to:\", base_path)\n",
        "else:\n",
        "    print(\" Zip already extracted.\")\n",
        "\n",
        "# Step 4: Setting working directory to the folder containing CSVs\n",
        "os.chdir(extract_path)\n",
        "print(\" Working directory set to:\", extract_path)\n",
        "\n",
        "# Step 5: Confirming\n",
        "print(\" Files found:\", os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWYS6xZ6QiJ",
        "outputId": "e509e360-f118-4230-838c-b9fe7761496a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ðŸ“¦ Zip already extracted.\n",
            "âœ… Working directory set to: /content/drive/MyDrive/projects/inshorts-data-scientist-task/test_data\n",
            "ðŸ“‚ Files found: ['.DS_Store', 'training_content', 'testing_content', 'event', 'devices']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T27pmlpL3RL4",
        "outputId": "903a9f6a-4860-4415-8ab2-5f614a067c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.DS_Store', 'training_content', 'testing_content', 'event', 'devices']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/MyDrive/test_data'\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(\" Google Drive mounted and path set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLFKiWfUOp7u",
        "outputId": "2310e557-3e90-41f2-f640-f4638ae283e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive mounted and path set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Loading user & content features\n",
        "user_df = pd.read_csv('user_features.csv')\n",
        "content_df = pd.read_csv('content_features.csv')\n",
        "\n",
        "#  Loading training interactions from event/ folder\n",
        "event_files = glob.glob('event/part-*.csv')\n",
        "train_df = pd.concat([pd.read_csv(f, on_bad_lines='skip') for f in event_files], ignore_index=True)\n",
        "\n",
        "#  Loading test candidates from testing_content\n",
        "test_files = glob.glob('testing_content/part-*.csv')\n",
        "test_candidates = pd.concat([pd.read_csv(f, on_bad_lines='skip') for f in test_files], ignore_index=True)\n",
        "\n",
        "#  Converting datetime strings to numeric timestamps\n",
        "for col in ['first_seen', 'last_seen']:\n",
        "    for df in [train_df, test_candidates]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col], errors='coerce').astype('int64') // 10**9\n",
        "\n",
        "#  Standardizing column names for merging\n",
        "train_df.rename(columns={'deviceid': 'deviceId', 'hashid': 'hashId'}, inplace=True)\n",
        "test_candidates.rename(columns={'deviceid': 'deviceId', 'hashid': 'hashId'}, inplace=True)\n",
        "user_df.rename(columns={'deviceid': 'deviceId'}, inplace=True)\n",
        "content_df.rename(columns={'hashid': 'hashId'}, inplace=True)\n",
        "\n",
        "#  Filtering positive events only\n",
        "event_types_we_want = ['CONTENT_CLICK']\n",
        "train_df = train_df[train_df['event_type'].isin(event_types_we_want)].copy()\n",
        "train_df['label'] = 1\n",
        "\n",
        "#  Sanity check\n",
        "print(f\"Users: {user_df.shape}, Content: {content_df.shape}, Training Events: {train_df.shape}, Test: {test_candidates.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFA4pknaK7TV",
        "outputId": "02f6d3ce-9b57-4256-b981-eae8f631e694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users: (8977, 7), Content: (14622, 4), Training Events: (0, 14), Test: (970, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Loading engineered features\n",
        "user_df = pd.read_csv('user_features.csv')\n",
        "content_df = pd.read_csv('content_features.csv')\n",
        "\n",
        "# Defining train/test file paths\n",
        "train_files = glob.glob('training_content/part-*.csv')\n",
        "test_files = glob.glob('testing_content/part-*.csv')\n",
        "\n",
        "# Loading training interactions (skip corrupted rows)\n",
        "train_df = pd.concat(\n",
        "    [pd.read_csv(f, on_bad_lines='skip') for f in train_files],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Loading test candidates (skip corrupted rows)\n",
        "test_candidates = pd.concat(\n",
        "    [pd.read_csv(f, on_bad_lines='skip') for f in test_files],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Loading events if needed\n",
        "event_files = glob.glob('event/part-*.csv')\n",
        "event_df = pd.concat(\n",
        "    [pd.read_csv(f, on_bad_lines='skip') for f in event_files],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "#  Summary print\n",
        "print(\"DataFrames loaded:\")\n",
        "print(f\" Users: {user_df.shape}\")\n",
        "print(f\" Content: {content_df.shape}\")\n",
        "print(f\" Training: {train_df.shape}\")\n",
        "print(f\" Testing: {test_candidates.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1GdG-s4Uc0r",
        "outputId": "2bbb81f2-5e2c-4753-ba6e-953ca23da7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrames loaded:\n",
            " Users: (8977, 7)\n",
            " Content: (14622, 4)\n",
            " Training: (8170, 12)\n",
            " Testing: (970, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_df columns:\", train_df.columns.tolist())\n",
        "print(\"user_df columns:\", user_df.columns.tolist())\n",
        "print(\"event_df columns:\", event_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP8eaPHjE9sK",
        "outputId": "185838e4-999e-4952-dff5-66303a232416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df columns: ['hashid', 'title', 'content', 'newsType', 'author', 'categories', 'hashtags', 'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n",
            "user_df columns: ['deviceId', 'event_count', 'total_time_spent', 'unique_content_count', 'first_seen', 'last_seen', 'active_days']\n",
            "event_df columns: ['deviceId', 'event_type', 'eventTimestamp', 'hashId', 'categoryWhenEventHappened', 'cardViewPosition', 'overallTimeSpent', 'searchTerm', 'relevancy_color', 'relevancy_topic', 'state', 'locality', 'district']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tckck2KTU3uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Feature Matrix Construction\n",
        "\n",
        "*Weâ€™re merging user-level and content-level features into a single DataFrame, then splitting into X (features) and y (labels).*"
      ],
      "metadata": {
        "id": "47sDa3zJgxNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV758uSBa_c3",
        "outputId": "179c1f40-7815-445a-d14f-4d087ffbb018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hashid', 'title', 'content', 'newsType', 'author', 'categories', 'hashtags', 'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Harmonizing keys before merging\n",
        "train_df = train_df.rename(columns={'hashid': 'hashId', 'deviceid': 'deviceId'})\n",
        "content_df = content_df.rename(columns={'hashid': 'hashId'})\n",
        "user_df = user_df.rename(columns={'deviceid': 'deviceId'})\n"
      ],
      "metadata": {
        "id": "hCmsR5xAOEg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Harmonizing key for content merge\n",
        "train_df = train_df.rename(columns={'hashid': 'hashId'})\n",
        "content_df = content_df.rename(columns={'hashid': 'hashId'})\n",
        "\n",
        "#  Merging content metadata into training data\n",
        "train = train_df.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Adding dummy label for structure (e.g., 1 for all rows)\n",
        "train['label'] = 1  # This is temporary; adjust based on actual labels if available\n",
        "\n",
        "#  Preparing feature matrix\n",
        "X = train.drop(columns=['hashId', 'label'])  # no deviceId here\n",
        "X = X.select_dtypes(include=['int64', 'float64'])\n",
        "y = train['label']\n",
        "\n",
        "#  Saving for reproducibility\n",
        "train.to_csv('train.csv', index=False)\n",
        "\n",
        "print(f\" X: {X.shape}, y distribution: \\n{y.value_counts(normalize=True)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-pQOFHJXG1W",
        "outputId": "a6970719-02f4-4400-c468-a4b2d5a0775f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… X: (8170, 3), y distribution: \n",
            "label\n",
            "1    1.0\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  Just in case: rename hashId again safely (won't hurt if repeated)\n",
        "train_df = train_df.rename(columns={'hashid': 'hashId'})\n",
        "content_df = content_df.rename(columns={'hashid': 'hashId'})\n",
        "event_df = event_df.rename(columns={'hashid': 'hashId', 'deviceid': 'deviceId'})\n",
        "user_df = user_df.rename(columns={'deviceid': 'deviceId'})\n",
        "\n",
        "#  Merging deviceId into train_df from event_df (event has both deviceId and hashId)\n",
        "event_meta = event_df[['deviceId', 'hashId']].drop_duplicates()\n",
        "train_df = train_df.merge(event_meta, on='hashId', how='left')\n",
        "\n",
        "#  Merging content features\n",
        "train = train_df.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Merging user features (after deviceId merge above)\n",
        "train = train.merge(user_df, on='deviceId', how='left')\n",
        "\n",
        "#  Adding dummy label (if not already there)\n",
        "if 'label' not in train.columns:\n",
        "    train['label'] = 1\n",
        "\n",
        "#  Feature matrix construction\n",
        "drop_cols = ['deviceId', 'hashId', 'title', 'content', 'author', 'categories',\n",
        "             'hashtags', 'newsDistrict', 'createdAt', 'updatedAt',\n",
        "             'newsLanguage', 'sourceName']\n",
        "\n",
        "X = train.drop(columns=drop_cols + ['label'], errors='ignore')\n",
        "X = X.select_dtypes(include=['int64', 'float64'])\n",
        "y = train['label']\n",
        "\n",
        "#  Saving for reproducibility\n",
        "train.to_csv('train.csv', index=False)\n",
        "\n",
        "#  Output\n",
        "print(f\" X: {X.shape}, y distribution:\\n{y.value_counts(normalize=True)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDABC6QJPkIa",
        "outputId": "7f1c616f-834c-4183-9fe0-d112855b75b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… X: (1420453, 7), y distribution:\n",
            "label\n",
            "1    1.0\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train DataFrame shape before feature merge:\", train_df.shape)\n",
        "print(\"User features keys:\", user_df.columns.tolist())\n",
        "print(\"Content features keys:\", content_df.columns.tolist())\n",
        "print(\"Train DataFrame sample keys:\", train_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtZFRZw1No_r",
        "outputId": "8d358f62-2512-49a1-bec6-4ed95d996071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame shape before feature merge: (8170, 12)\n",
            "User features keys: ['deviceId', 'event_count', 'total_time_spent', 'unique_content_count', 'first_seen', 'last_seen', 'active_days']\n",
            "Content features keys: ['hashId', 'event_count', 'unique_viewers', 'avg_time_spent']\n",
            "Train DataFrame sample keys: ['hashId', 'title', 'content', 'newsType', 'author', 'categories', 'hashtags', 'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Model Training & Validation\n",
        "\n",
        "*Weâ€™re splitting the data, training a LightGBM classifier with early stopping, and evaluating via AUC.*"
      ],
      "metadata": {
        "id": "-yhEAh0HhBO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive_df shape:\", positive_df.shape)\n",
        "print(\"negative_df shape:\", negative_df.shape)\n",
        "print(\"train_df shape:\", train_df.shape)\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUwFANgleKDs",
        "outputId": "7080fe52-39b0-4f0d-d693-8086d0293e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive_df shape: (0, 3)\n",
            "negative_df shape: (0, 3)\n",
            "train_df shape: (0, 3)\n",
            "Empty DataFrame\n",
            "Columns: [deviceId, hashId, label]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 3: Rebuilding training set from event logs\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Getting all positive samples â€” clicks only\n",
        "positive_df = event_df[event_df['event_type'] == 'click'][['deviceId', 'hashId']].drop_duplicates()\n",
        "positive_df['label'] = 1\n",
        "\n",
        "# Step 2: Creating negative samples (user-content pairs not clicked)\n",
        "all_users = positive_df['deviceId'].unique()\n",
        "all_contents = event_df['hashId'].unique()\n",
        "\n",
        "negatives = []\n",
        "np.random.seed(42)\n",
        "\n",
        "for user in all_users:\n",
        "    clicked = set(positive_df[positive_df['deviceId'] == user]['hashId'])\n",
        "    available = list(set(all_contents) - clicked)\n",
        "\n",
        "    # Skipping if no options to sample from\n",
        "    if len(available) == 0:\n",
        "        continue\n",
        "\n",
        "    # Sample 3 negative examples per user\n",
        "    sample_size = min(3, len(available))\n",
        "    sampled = np.random.choice(available, size=sample_size, replace=False)\n",
        "\n",
        "    for c in sampled:\n",
        "        negatives.append([user, c, 0])\n",
        "\n",
        "negative_df = pd.DataFrame(negatives, columns=['deviceId', 'hashId', 'label'])\n",
        "\n",
        "# Step 3: Combining and shuffling\n",
        "train_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "train_df = train_df.drop_duplicates().sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Checking class balance\n",
        "print(\" Label distribution AFTER rebuild:\")\n",
        "print(train_df['label'].value_counts(normalize=True))\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYPqXZ4jeoyt",
        "outputId": "43cc3e90-77e4-46ad-edf0-b3862486e1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Label distribution AFTER rebuild:\n",
            "Series([], Name: proportion, dtype: float64)\n",
            "Empty DataFrame\n",
            "Columns: [deviceId, hashId, label]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(event_df['event_type'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpTrRTxhfHlc",
        "outputId": "789086cc-3265-41f2-eace-e2f46474d004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "event_type\n",
            "TimeSpent-Front              3480131\n",
            "TimeSpent-Back                 44933\n",
            "News Bookmarked                10870\n",
            "News Shared                     3517\n",
            "News Unbookmarked               2275\n",
            "Relevancy Option Selected       1312\n",
            "Search                          1123\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#  Step 1: Using 'News Bookmarked' as positive signal\n",
        "positive_df = event_df[event_df['event_type'] == 'News Bookmarked'][['deviceId', 'hashId']].drop_duplicates()\n",
        "positive_df['label'] = 1\n",
        "\n",
        "#  Step 2: Generating negative samples\n",
        "all_users = user_df['deviceId'].unique()\n",
        "all_content = content_df['hashId'].unique()\n",
        "num_negatives = len(positive_df)\n",
        "\n",
        "np.random.seed(42)\n",
        "neg_users = np.random.choice(all_users, size=num_negatives)\n",
        "neg_content = np.random.choice(all_content, size=num_negatives)\n",
        "\n",
        "negative_df = pd.DataFrame({\n",
        "    'deviceId': neg_users,\n",
        "    'hashId': neg_content\n",
        "})\n",
        "\n",
        "#  Ensuring negatives are not positives\n",
        "negative_df = negative_df.merge(\n",
        "    positive_df[['deviceId', 'hashId']],\n",
        "    on=['deviceId', 'hashId'],\n",
        "    how='left',\n",
        "    indicator=True\n",
        ")\n",
        "\n",
        "negative_df = negative_df[negative_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
        "negative_df['label'] = 0\n",
        "\n",
        "# âœ… Step 3: Combining and shuffling\n",
        "train_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#  Sanity check\n",
        "print(\"âœ… Label distribution AFTER rebuild:\")\n",
        "print(train_df['label'].value_counts(normalize=True))\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0BTzltwf69E",
        "outputId": "0dae900a-c707-40f7-c5f1-d13530e71867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Label distribution AFTER rebuild:\n",
            "label\n",
            "1    0.500049\n",
            "0    0.499951\n",
            "Name: proportion, dtype: float64\n",
            "                               deviceId      hashId  label\n",
            "0  7cf72e69-0e42-47b7-9085-b3f46ca8be85  k7epp86p-1      0\n",
            "1  81957c0d-44a4-45e8-b0e7-438f9aa1b9fc  d6ghkpsd-1      0\n",
            "2  12b6f877-193b-456f-af55-994a98ab5123  hr1rbbai-1      0\n",
            "3  049b40db-bfda-4f61-9118-708e831e9823  ysu3593v-1      1\n",
            "4  7e5c2cb6-4761-48f4-b258-9f30c98ead45  zc2frrhg-1      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "#  Final merge to enrich with features\n",
        "train = train_df.merge(user_df, on='deviceId', how='left')\n",
        "train = train.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Feature prep\n",
        "drop_cols = ['deviceId', 'hashId', 'title', 'content', 'author', 'categories', 'hashtags',\n",
        "             'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n",
        "X = train.drop(columns=drop_cols, errors='ignore')\n",
        "X = X.select_dtypes(include=['int64', 'float64'])\n",
        "y = train['label']\n",
        "\n",
        "#  Sanity check\n",
        "print(\"Label distribution:\\n\", y.value_counts(normalize=True))\n",
        "\n",
        "#  Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "#  Model training\n",
        "model = LGBMClassifier(n_estimators=200, random_state=42)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    callbacks=[lgb.early_stopping(20)]\n",
        ")\n",
        "\n",
        "#  Evaluation\n",
        "val_preds = model.predict_proba(X_val)[:, 1]\n",
        "auc_score = roc_auc_score(y_val, val_preds)\n",
        "print(f\"âœ… Final Validation AUC: {auc_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugbQ2_GSgPrc",
        "outputId": "13d06b38-1d38-41e5-8ccd-7a8b7e8f848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution:\n",
            " label\n",
            "1    0.500049\n",
            "0    0.499951\n",
            "Name: proportion, dtype: float64\n",
            "[LightGBM] [Info] Number of positive: 8109, number of negative: 8107\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1561\n",
            "[LightGBM] [Info] Number of data points in the train set: 16216, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500062 -> initscore=0.000247\n",
            "[LightGBM] [Info] Start training from score 0.000247\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "Early stopping, best iteration is:\n",
            "[152]\tvalid_0's binary_logloss: 1.20822e-07\n",
            "âœ… Final Validation AUC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Prediction & Submission\n",
        "\n",
        "*Weâ€™re loading (or regenerating) test candidates, merging features, scoring with our trained model, and exporting the top-50 predictions.*\n"
      ],
      "metadata": {
        "id": "M902a7bchNHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_candidates = test_candidates.rename(columns={'deviceid': 'deviceId', 'hashid': 'hashId'})\n"
      ],
      "metadata": {
        "id": "pu9DXlCXivXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Columns in test_candidates:\\n\", test_candidates.columns.tolist())\n",
        "print(\" First few rows:\\n\", test_candidates.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0pD9Fp8Euan",
        "outputId": "55f83ea0-3c85-4ed8-c7bf-615431cfb5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Columns in test_candidates:\n",
            " ['hashId', 'title', 'content', 'newsType', 'author', 'categories', 'hashtags', 'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n",
            "ðŸ”¢ First few rows:\n",
            "        hashId                                              title  \\\n",
            "0  zdw0jrig-1  Redmi 12 5G will be a game-changer for 5G conn...   \n",
            "1  y5pfnbmp-1  Limited seats left for Hero Vired & MITâ€™s Prog...   \n",
            "2  eo2eyhgk-1  Heavy to very heavy rainfall warning issued fo...   \n",
            "3  fknyydal-1  Which 14 teams have qualified for 20-team T20 ...   \n",
            "4  61ogen4w-1  42-year-old woman shot dead near her house in ...   \n",
            "\n",
            "                                             content newsType  \\\n",
            "0  Xiaomi will debut Redmi 12 5G alongside Redmi ...     NEWS   \n",
            "1  Hero Group's EdTech company Hero Vired & MIT l...     NEWS   \n",
            "2  IMD has issued heavy to very heavy rainfall wa...     NEWS   \n",
            "3  Ireland and Scotland have qualified for the 20...     NEWS   \n",
            "4  A 42-year-old woman was shot dead near her hou...     NEWS   \n",
            "\n",
            "                     author  categories hashtags newsDistrict  \\\n",
            "0  593f9d1f81ef171ab3b63a2d  technology      NaN          NaN   \n",
            "1  593f9d1f81ef171ab3b63a2d   education      NaN          NaN   \n",
            "2  5f70de9bd43821580e6d7022    national      NaN          NaN   \n",
            "3  5f70de9bd43821580e6d7022      sports      NaN          NaN   \n",
            "4  5f70de9bd43821580e6d7022    national      NaN          NaN   \n",
            "\n",
            "                  createdAt                 updatedAt newsLanguage sourceName  \n",
            "0  2023-07-27T07:06:41.000Z  2023-07-27T07:06:41.000Z      english     Xiaomi  \n",
            "1  2023-07-27T04:30:50.000Z  2023-07-27T04:30:50.000Z      english  vired.com  \n",
            "2  2023-07-27T16:23:53.000Z  2023-07-27T17:12:11.285Z      english        IMD  \n",
            "3  2023-07-27T14:29:59.000Z  2023-07-27T14:29:59.000Z      english        ICC  \n",
            "4  2023-07-27T17:07:31.000Z  2023-07-27T17:07:31.000Z      english        ABP  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#  Mounting Google Drive (already mounted, so this is optional)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Setting correct project path\n",
        "project_path = '/content/drive/MyDrive/test_data'\n",
        "os.chdir(project_path)\n",
        "\n",
        "#  FIXED: Correct path to the file (only one test_data in path)\n",
        "device_path = 'devices/part-00000-cdb2cdd7-9d14-4000-b947-4d0475444217-c000.csv'\n",
        "\n",
        "#  Loadiing and standardize column\n",
        "devices = pd.read_csv(device_path)\n",
        "devices = devices.rename(columns={'deviceid': 'deviceId'})\n",
        "\n",
        "#  Checking\n",
        "print(\"âœ… Devices loaded:\", devices.shape)\n",
        "print(devices[['deviceId']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkHSSBG6eZ_g",
        "outputId": "d9025d0f-41f0-4b7a-8281-fe9df78a0789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Devices loaded: (10400, 11)\n",
            "                               deviceId\n",
            "0  197b123e-eb9e-4fc1-a32d-aa86aaea425e\n",
            "1  3c33c537-7c6c-40f5-835c-f997e883cae2\n",
            "2  6c7be5d0-d4d8-469f-91be-8055021ceef9\n",
            "3  0801af66-0a6f-4fdd-82a9-c2b15757b8f5\n",
            "4  78b3c7a7-5881-42dc-9f8e-b4fc27f94360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  STEP 4: Predicting and Generate Submission\n",
        "\n",
        "# Step 1: Preparing test candidates â†’ merge each test user with every test content\n",
        "test_candidates = devices[['deviceId']].assign(dummy=1).merge(\n",
        "    content_df[['hashId']].assign(dummy=1), on='dummy'\n",
        ").drop(columns=['dummy'])\n",
        "\n",
        "# Step 2: Merging user & content features into test set\n",
        "X_test = test_candidates.merge(user_df, on='deviceId', how='left')\n",
        "X_test = X_test.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "# Step 3: Converting datetime columns (if they exist)\n",
        "for col in ['first_seen', 'last_seen']:\n",
        "    if col in X_test.columns:\n",
        "        X_test[col] = pd.to_datetime(X_test[col], errors='coerce').astype('int64') // 10**9\n",
        "\n",
        "# Step 4: Aligning columns with training data\n",
        "X_test_model = X_test[X.columns]  # X is the training feature set from Step 3\n",
        "\n",
        "# Step 5: Predicting probabilities\n",
        "X_test['label'] = model.predict_proba(X_test_model)[:, 1]\n",
        "\n",
        "# Step 6: Sorting and select top 50 content per user\n",
        "top_50 = (\n",
        "    X_test.sort_values(['deviceId', 'label'], ascending=[True, False])\n",
        "          .groupby('deviceId')\n",
        "          .head(50)\n",
        "          .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Step 7: Exporting final submission\n",
        "top_50[['deviceId', 'hashId', 'label']].to_csv('submission.csv', index=False)\n",
        "print(\" Submission file 'submission.csv' created with shape:\", top_50.shape)\n",
        "top_50[['deviceId', 'hashId', 'label']].head()\n"
      ],
      "metadata": {
        "id": "hnhraCarfAfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "#  Loading features and model inputs\n",
        "user_df = pd.read_csv('/content/drive/MyDrive/test_data/user_features.csv')\n",
        "content_df = pd.read_csv('/content/drive/MyDrive/test_data/content_features.csv')\n",
        "devices = pd.read_csv('/content/drive/MyDrive/test_data/devices/part-00000-cdb2cdd7-9d14-4000-b947-4d0475444217-c000.csv')\n",
        "\n",
        "#  Harmonizing naming\n",
        "user_df.rename(columns={'deviceid': 'deviceId'}, inplace=True)\n",
        "content_df.rename(columns={'hashid': 'hashId'}, inplace=True)\n",
        "devices.rename(columns={'deviceid': 'deviceId'}, inplace=True)\n",
        "\n",
        "#  Preparing test user list\n",
        "test_users = devices[['deviceId']].drop_duplicates()\n"
      ],
      "metadata": {
        "id": "3QMdI3INiDDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['deviceId', 'hashId', 'title', 'content', 'author', 'categories', 'hashtags',\n",
        "             'newsDistrict', 'createdAt', 'updatedAt', 'newsLanguage', 'sourceName']\n",
        "train = pd.read_csv('/content/drive/MyDrive/test_data/train.csv')  # If you saved it before\n",
        "\n",
        "X = train.drop(columns=drop_cols, errors='ignore')\n",
        "X = X.select_dtypes(include=['int64', 'float64'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVvvvoApiogp",
        "outputId": "151177ec-cf20-40de-ca39-a2f24ebbcc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-2243161645.py:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train = pd.read_csv('/content/drive/MyDrive/test_data/train.csv')  # If you saved it before\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib  # if you had saved model\n"
      ],
      "metadata": {
        "id": "RSiZ2rqfni8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "#  Step 1: Getting list of all event files (match actual filenames)\n",
        "event_files = glob.glob('/content/drive/MyDrive/test_data/event/part-*.csv')\n",
        "print(f\"ðŸ“¦ Found {len(event_files)} event files.\")\n",
        "\n",
        "#  Step 2: Loading only essential columns to reduce memory load\n",
        "use_columns = ['deviceId', 'hashId', 'event_type']\n",
        "\n",
        "#  Step 3: Loading in chunks and concatenate\n",
        "event_df = pd.concat([\n",
        "    pd.read_csv(f, usecols=use_columns, on_bad_lines='skip', low_memory=False)\n",
        "    for f in event_files\n",
        "], ignore_index=True)\n",
        "\n",
        "#  Step 4: Quick sanity check\n",
        "print(\"âœ… Loaded event_df shape:\", event_df.shape)\n",
        "print(\"ðŸ§¾ Event types distribution:\\n\", event_df['event_type'].value_counts(dropna=False))\n",
        "print(\"ðŸ”Ž Sample:\\n\", event_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhhHTSRn_XSt",
        "outputId": "b5871721-3b96-4bc6-a4fe-82d849be93df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Found 4 event files.\n",
            "âœ… Loaded event_df shape: (3544161, 3)\n",
            "ðŸ§¾ Event types distribution:\n",
            " event_type\n",
            "TimeSpent-Front              3480131\n",
            "TimeSpent-Back                 44933\n",
            "News Bookmarked                10870\n",
            "News Shared                     3517\n",
            "News Unbookmarked               2275\n",
            "Relevancy Option Selected       1312\n",
            "Search                          1123\n",
            "Name: count, dtype: int64\n",
            "ðŸ”Ž Sample:\n",
            "                                deviceId                 event_type      hashId\n",
            "0  1c53a149-303d-486e-ac62-0b9c9e469cda                     Search     Unknown\n",
            "1  68738cd7-ae73-49c7-90d0-9829516f434e                     Search     Unknown\n",
            "2  afe21f00-2d68-4a73-9bc6-f19be7f2226a  Relevancy Option Selected     Unknown\n",
            "3  42b52a10-0a8e-4d25-a886-a5f7323ea8c0                     Search     Unknown\n",
            "4  fb242092-49e6-45dd-b764-1f1bf34a2e7d            TimeSpent-Front  07ov7cef-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#  Step 1: Positive pairs â†’ Users who spent time on a content card\n",
        "positive_df = event_df[event_df['event_type'] == 'TimeSpent-Front'][['deviceId', 'hashId']].drop_duplicates()\n",
        "positive_df['label'] = 1\n",
        "\n",
        "print(\" Positive samples:\", positive_df.shape)\n",
        "\n",
        "#  Step 2: Negative samples â†’ Random deviceId/hashId combos not in positive_df\n",
        "unique_users = event_df['deviceId'].dropna().unique()\n",
        "unique_contents = event_df['hashId'].dropna().unique()\n",
        "\n",
        "# Matching number of positives\n",
        "num_negatives = len(positive_df)\n",
        "np.random.seed(42)\n",
        "\n",
        "neg_users = np.random.choice(unique_users, size=num_negatives, replace=True)\n",
        "neg_contents = np.random.choice(unique_contents, size=num_negatives, replace=True)\n",
        "\n",
        "negative_df = pd.DataFrame({'deviceId': neg_users, 'hashId': neg_contents})\n",
        "negative_df = negative_df.merge(positive_df[['deviceId', 'hashId']], on=['deviceId', 'hashId'], how='left', indicator=True)\n",
        "negative_df = negative_df[negative_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
        "negative_df['label'] = 0\n",
        "\n",
        "print(\" Negative samples:\", negative_df.shape)\n",
        "\n",
        "#  Step 3: Combining\n",
        "train_df = pd.concat([positive_df, negative_df], ignore_index=True).drop_duplicates()\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#  Final check\n",
        "print(\" Final train_df shape:\", train_df.shape)\n",
        "print(train_df['label'].value_counts(normalize=True))\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1695YKx9FgaV",
        "outputId": "a3dbbbcc-6b4f-40f4-8ff1-062992258e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Positive samples: (2765385, 3)\n",
            "âœ… Negative samples: (2707319, 3)\n",
            "âœ… Final train_df shape: (5444510, 3)\n",
            "label\n",
            "1    0.507922\n",
            "0    0.492078\n",
            "Name: proportion, dtype: float64\n",
            "                               deviceId      hashId  label\n",
            "0  b4bebd7f-0729-4e0e-a88b-b51853d0b543  hhwllgvi-1      0\n",
            "1  c0cec7eb-b4be-4e9b-9524-a2f40d4c4275  jlfeeiqj-1      1\n",
            "2  1b51faf2-4b7a-4d77-9125-6ce066cd2d70  eelh3eej-1      0\n",
            "3  d733445b-3a0e-4c67-b84c-d305605cd62c  tn2tzgfw-1      0\n",
            "4  4f10065e-faa1-49f1-b8fc-93a6e186fb26  zn5jq7m9-1      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Loading user + content features if not already\n",
        "user_df = pd.read_csv('/content/drive/MyDrive/test_data/user_features.csv')\n",
        "content_df = pd.read_csv('/content/drive/MyDrive/test_data/content_features.csv')\n",
        "\n",
        "#  Harmonizing columns\n",
        "user_df = user_df.rename(columns={'deviceid': 'deviceId'})\n",
        "content_df = content_df.rename(columns={'hashid': 'hashId'})\n",
        "\n",
        "#  Merging features into train_df\n",
        "train = train_df.merge(user_df, on='deviceId', how='left')\n",
        "train = train.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Feature engineering: remove ID columns & non-numeric\n",
        "X = train.drop(columns=['deviceId', 'hashId', 'label'], errors='ignore')\n",
        "X = X.select_dtypes(include=['int64', 'float64'])\n",
        "y = train['label']\n",
        "\n",
        "#  LightGBM Training (fast with early stopping)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LGBMClassifier(n_estimators=200, random_state=42)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    callbacks=[lgb.early_stopping(20)]\n",
        ")\n",
        "\n",
        "val_preds = model.predict_proba(X_val)[:, 1]\n",
        "auc_score = roc_auc_score(y_val, val_preds)\n",
        "\n",
        "print(f\" Final Validation AUC: {auc_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E1uk8kPGLS8",
        "outputId": "225ebae5-cf48-4ddd-a8fc-70521a9ddeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2212308, number of negative: 2143300\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.511745 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1558\n",
            "[LightGBM] [Info] Number of data points in the train set: 4355608, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507922 -> initscore=0.031690\n",
            "[LightGBM] [Info] Start training from score 0.031690\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "Early stopping, best iteration is:\n",
            "[114]\tvalid_0's binary_logloss: 0.236029\n",
            "âœ… Final Validation AUC: 0.9653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = list(X.columns)\n"
      ],
      "metadata": {
        "id": "Gt3RrCqyO8FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  RAM-safe dry run with just 50 users\n",
        "test_users_sample = test_users.iloc[:50].copy()\n",
        "\n",
        "#  Using test_candidates instead of undefined `test_articles`\n",
        "content_ids = test_candidates[['hashId']].drop_duplicates()\n",
        "\n",
        "#  Creating all combinations of users Ã— content\n",
        "test_batch = test_users_sample.assign(key=1).merge(content_ids.assign(key=1), on='key').drop('key', axis=1)\n",
        "\n",
        "#  Merging features\n",
        "test_batch = test_batch.merge(user_df, on='deviceId', how='left')\n",
        "test_batch = test_batch.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Converting datetime columns if present\n",
        "for col in ['first_seen', 'last_seen']:\n",
        "    if col in test_batch.columns:\n",
        "        test_batch[col] = pd.to_datetime(test_batch[col], errors='coerce').astype('int64') // 10**9\n",
        "\n",
        "#  Matching feature columns (ensure it's defined; typically from training stage)\n",
        "test_batch_X = test_batch[feature_cols].select_dtypes(include=['int64', 'float64']).fillna(0)\n",
        "\n",
        "#  Predicting\n",
        "test_batch['label'] = model.predict_proba(test_batch_X)[:, 1]\n",
        "\n",
        "#  Selecting top 50 per user\n",
        "top_sample = (\n",
        "    test_batch.sort_values(['deviceId', 'label'], ascending=[True, False])\n",
        "              .groupby('deviceId')\n",
        "              .head(50)\n",
        "              .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\" Dry run passed. Sample shape:\", top_sample.shape)\n",
        "top_sample.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "dAmnkP1yO_sg",
        "outputId": "f30a467e-9485-49a7-8661-005b65c08543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dry run passed. Sample shape: (2500, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               deviceId      hashId  event_count_x  \\\n",
              "0  07d18cd7-e320-4f68-9198-4bc78f177e7d  zdw0jrig-1            NaN   \n",
              "1  07d18cd7-e320-4f68-9198-4bc78f177e7d  y5pfnbmp-1            NaN   \n",
              "2  07d18cd7-e320-4f68-9198-4bc78f177e7d  eo2eyhgk-1            NaN   \n",
              "3  07d18cd7-e320-4f68-9198-4bc78f177e7d  fknyydal-1            NaN   \n",
              "4  07d18cd7-e320-4f68-9198-4bc78f177e7d  61ogen4w-1            NaN   \n",
              "\n",
              "   total_time_spent  unique_content_count  first_seen   last_seen  \\\n",
              "0               NaN                   NaN -9223372037 -9223372037   \n",
              "1               NaN                   NaN -9223372037 -9223372037   \n",
              "2               NaN                   NaN -9223372037 -9223372037   \n",
              "3               NaN                   NaN -9223372037 -9223372037   \n",
              "4               NaN                   NaN -9223372037 -9223372037   \n",
              "\n",
              "   active_days  event_count_y  unique_viewers  avg_time_spent     label  \n",
              "0          NaN            NaN             NaN             NaN  0.000126  \n",
              "1          NaN            NaN             NaN             NaN  0.000126  \n",
              "2          NaN            NaN             NaN             NaN  0.000126  \n",
              "3          NaN            NaN             NaN             NaN  0.000126  \n",
              "4          NaN            NaN             NaN             NaN  0.000126  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da7fc4ad-11d0-49f9-9818-e12650e98624\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deviceId</th>\n",
              "      <th>hashId</th>\n",
              "      <th>event_count_x</th>\n",
              "      <th>total_time_spent</th>\n",
              "      <th>unique_content_count</th>\n",
              "      <th>first_seen</th>\n",
              "      <th>last_seen</th>\n",
              "      <th>active_days</th>\n",
              "      <th>event_count_y</th>\n",
              "      <th>unique_viewers</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>zdw0jrig-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>y5pfnbmp-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>eo2eyhgk-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>fknyydal-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>61ogen4w-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>-9223372037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da7fc4ad-11d0-49f9-9818-e12650e98624')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da7fc4ad-11d0-49f9-9818-e12650e98624 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da7fc4ad-11d0-49f9-9818-e12650e98624');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f436ee03-7c5f-4b81-ab2f-7831d7fea27a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f436ee03-7c5f-4b81-ab2f-7831d7fea27a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f436ee03-7c5f-4b81-ab2f-7831d7fea27a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_sample",
              "summary": "{\n  \"name\": \"top_sample\",\n  \"rows\": 2500,\n  \"fields\": [\n    {\n      \"column\": \"deviceId\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"36e9df7d-85e5-47e4-8ee0-349f56590032\",\n          \"95a07b6b-0657-4947-8d50-93d5a4619f80\",\n          \"78e6f9f9-8836-4dce-b57c-85fc80dc1ed0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashId\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"j6ncpcwb-1\",\n          \"0p5uwplc-1\",\n          \"jg0p3eoy-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_count_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_time_spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_content_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_seen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -9223372037,\n        \"max\": -9223372037,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_seen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -9223372037,\n        \"max\": -9223372037,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"active_days\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_count_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_viewers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_time_spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5483848332854853e-18,\n        \"min\": 0.00012637134781967957,\n        \"max\": 0.00012637134781967957,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#  Loading test articles using exact filename\n",
        "test_articles_path = '/content/drive/MyDrive/test_data/testing_content/part-00000-8be13c58-b74d-4e30-8877-c8b5e168035a-c000.csv'\n",
        "test_articles = pd.read_csv(test_articles_path, on_bad_lines='skip')\n",
        "test_articles = test_articles.rename(columns={'hashid': 'hashId'})\n",
        "\n",
        "#  Using existing test_users (you should already have this from device file)\n",
        "test_users_sample = test_users.iloc[:50].copy()  # you can bump this number up carefully\n",
        "\n",
        "#  Creating cartesian product (safe for small sample)\n",
        "test_candidates = test_users_sample.assign(key=1).merge(\n",
        "    test_articles[['hashId']].assign(key=1), on='key'\n",
        ").drop(columns='key')\n",
        "\n",
        "#  Merging features\n",
        "test_candidates = test_candidates.merge(user_df, on='deviceId', how='left')\n",
        "test_candidates = test_candidates.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "#  Preparing feature matrix\n",
        "X_test_model = test_candidates[[col for col in X.columns if col in test_candidates.columns]]\n",
        "test_candidates['label'] = model.predict_proba(X_test_model)[:, 1]\n",
        "\n",
        "#  Getting top-50 per user\n",
        "top_50_sample = (\n",
        "    test_candidates.sort_values(['deviceId', 'label'], ascending=[True, False])\n",
        "    .groupby('deviceId')\n",
        "    .head(50)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "#  Saving sample to disk (optional)\n",
        "top_50_sample[['deviceId', 'hashId', 'label']].to_csv('sample_submission.csv', index=False)\n",
        "\n",
        "# Preview\n",
        "print(\" Dry run passed. Sample shape:\", top_50_sample.shape)\n",
        "top_50_sample.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "57vK06NhSV1U",
        "outputId": "351d10cc-987e-4317-f63e-92dbda99bc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dry run passed. Sample shape: (2500, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               deviceId      hashId  event_count_x  \\\n",
              "0  07d18cd7-e320-4f68-9198-4bc78f177e7d  zdw0jrig-1            NaN   \n",
              "1  07d18cd7-e320-4f68-9198-4bc78f177e7d  y5pfnbmp-1            NaN   \n",
              "2  07d18cd7-e320-4f68-9198-4bc78f177e7d  eo2eyhgk-1            NaN   \n",
              "3  07d18cd7-e320-4f68-9198-4bc78f177e7d  fknyydal-1            NaN   \n",
              "4  07d18cd7-e320-4f68-9198-4bc78f177e7d  61ogen4w-1            NaN   \n",
              "\n",
              "   total_time_spent  unique_content_count first_seen last_seen  active_days  \\\n",
              "0               NaN                   NaN        NaN       NaN          NaN   \n",
              "1               NaN                   NaN        NaN       NaN          NaN   \n",
              "2               NaN                   NaN        NaN       NaN          NaN   \n",
              "3               NaN                   NaN        NaN       NaN          NaN   \n",
              "4               NaN                   NaN        NaN       NaN          NaN   \n",
              "\n",
              "   event_count_y  unique_viewers  avg_time_spent     label  \n",
              "0            NaN             NaN             NaN  0.000126  \n",
              "1            NaN             NaN             NaN  0.000126  \n",
              "2            NaN             NaN             NaN  0.000126  \n",
              "3            NaN             NaN             NaN  0.000126  \n",
              "4            NaN             NaN             NaN  0.000126  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e096645-283c-4dff-afde-7306339e0a6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deviceId</th>\n",
              "      <th>hashId</th>\n",
              "      <th>event_count_x</th>\n",
              "      <th>total_time_spent</th>\n",
              "      <th>unique_content_count</th>\n",
              "      <th>first_seen</th>\n",
              "      <th>last_seen</th>\n",
              "      <th>active_days</th>\n",
              "      <th>event_count_y</th>\n",
              "      <th>unique_viewers</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>zdw0jrig-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>y5pfnbmp-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>eo2eyhgk-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>fknyydal-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07d18cd7-e320-4f68-9198-4bc78f177e7d</td>\n",
              "      <td>61ogen4w-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e096645-283c-4dff-afde-7306339e0a6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e096645-283c-4dff-afde-7306339e0a6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e096645-283c-4dff-afde-7306339e0a6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b8a7947a-0e40-4f44-8a85-e40b4fc051ba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8a7947a-0e40-4f44-8a85-e40b4fc051ba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b8a7947a-0e40-4f44-8a85-e40b4fc051ba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top_50_sample",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#  Loading test articles again if needed\n",
        "test_articles_path = '/content/drive/MyDrive/test_data/testing_content/part-00000-8be13c58-b74d-4e30-8877-c8b5e168035a-c000.csv'\n",
        "test_articles = pd.read_csv(test_articles_path, on_bad_lines='skip')\n",
        "test_articles = test_articles.rename(columns={'hashid': 'hashId'})\n",
        "\n",
        "#  Getting all unique test users\n",
        "test_users_unique = test_users[['deviceId']].drop_duplicates().reset_index(drop=True)\n",
        "print(f\" Total test users: {len(test_users_unique)}\")\n",
        "\n",
        "#  Creating content pool (unique hashId)\n",
        "content_ids = test_articles[['hashId']].drop_duplicates()\n",
        "\n",
        "#  Preparing holder for final top-50 predictions\n",
        "final_submissions = []\n",
        "\n",
        "#  Batch loop (adjust batch_size for your available RAM)\n",
        "batch_size = 250  # Safe for ~10GB RAM\n",
        "for start in range(0, len(test_users_unique), batch_size):\n",
        "    end = start + batch_size\n",
        "    batch_users = test_users_unique.iloc[start:end].copy()\n",
        "\n",
        "    print(f\" Processing users {start} to {end}...\")\n",
        "\n",
        "    # 1. Creating user Ã— content pairs\n",
        "    batch_candidates = batch_users.assign(key=1).merge(\n",
        "        content_ids.assign(key=1), on='key'\n",
        "    ).drop(columns='key')\n",
        "\n",
        "    # 2. Merging user and content features\n",
        "    batch = batch_candidates.merge(user_df, on='deviceId', how='left')\n",
        "    batch = batch.merge(content_df, on='hashId', how='left')\n",
        "\n",
        "    # 3. Feature prep\n",
        "    batch_X = batch[[col for col in X.columns if col in batch.columns]]\n",
        "    batch['label'] = model.predict_proba(batch_X)[:, 1]\n",
        "\n",
        "    # 4. Top-50 per user\n",
        "    top_50 = (\n",
        "        batch.sort_values(['deviceId', 'label'], ascending=[True, False])\n",
        "        .groupby('deviceId')\n",
        "        .head(50)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    final_submissions.append(top_50[['deviceId', 'hashId', 'label']])\n",
        "\n",
        "    # 5. Cleaning up memory\n",
        "    del batch, batch_X, top_50, batch_candidates\n",
        "    import gc; gc.collect()\n",
        "\n",
        "#  Combining all batches\n",
        "submission_df = pd.concat(final_submissions, ignore_index=True)\n",
        "\n",
        "#  Saving final submission\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\" Submission saved as submission.csv\")\n",
        "print(submission_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekTecogjS4Cv",
        "outputId": "86524a08-e28e-4c08-b35c-f7a887209bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¢ Total test users: 10400\n",
            "ðŸ”„ Processing users 0 to 250...\n",
            "ðŸ”„ Processing users 250 to 500...\n",
            "ðŸ”„ Processing users 500 to 750...\n",
            "ðŸ”„ Processing users 750 to 1000...\n",
            "ðŸ”„ Processing users 1000 to 1250...\n",
            "ðŸ”„ Processing users 1250 to 1500...\n",
            "ðŸ”„ Processing users 1500 to 1750...\n",
            "ðŸ”„ Processing users 1750 to 2000...\n",
            "ðŸ”„ Processing users 2000 to 2250...\n",
            "ðŸ”„ Processing users 2250 to 2500...\n",
            "ðŸ”„ Processing users 2500 to 2750...\n",
            "ðŸ”„ Processing users 2750 to 3000...\n",
            "ðŸ”„ Processing users 3000 to 3250...\n",
            "ðŸ”„ Processing users 3250 to 3500...\n",
            "ðŸ”„ Processing users 3500 to 3750...\n",
            "ðŸ”„ Processing users 3750 to 4000...\n",
            "ðŸ”„ Processing users 4000 to 4250...\n",
            "ðŸ”„ Processing users 4250 to 4500...\n",
            "ðŸ”„ Processing users 4500 to 4750...\n",
            "ðŸ”„ Processing users 4750 to 5000...\n",
            "ðŸ”„ Processing users 5000 to 5250...\n",
            "ðŸ”„ Processing users 5250 to 5500...\n",
            "ðŸ”„ Processing users 5500 to 5750...\n",
            "ðŸ”„ Processing users 5750 to 6000...\n",
            "ðŸ”„ Processing users 6000 to 6250...\n",
            "ðŸ”„ Processing users 6250 to 6500...\n",
            "ðŸ”„ Processing users 6500 to 6750...\n",
            "ðŸ”„ Processing users 6750 to 7000...\n",
            "ðŸ”„ Processing users 7000 to 7250...\n",
            "ðŸ”„ Processing users 7250 to 7500...\n",
            "ðŸ”„ Processing users 7500 to 7750...\n",
            "ðŸ”„ Processing users 7750 to 8000...\n",
            "ðŸ”„ Processing users 8000 to 8250...\n",
            "ðŸ”„ Processing users 8250 to 8500...\n",
            "ðŸ”„ Processing users 8500 to 8750...\n",
            "ðŸ”„ Processing users 8750 to 9000...\n",
            "ðŸ”„ Processing users 9000 to 9250...\n",
            "ðŸ”„ Processing users 9250 to 9500...\n",
            "ðŸ”„ Processing users 9500 to 9750...\n",
            "ðŸ”„ Processing users 9750 to 10000...\n",
            "ðŸ”„ Processing users 10000 to 10250...\n",
            "ðŸ”„ Processing users 10250 to 10500...\n",
            "ðŸŽ‰ Submission saved as submission.csv\n",
            "                               deviceId      hashId     label\n",
            "0  01b1bf81-d314-4612-97e9-517477823df3  zdw0jrig-1  0.000126\n",
            "1  01b1bf81-d314-4612-97e9-517477823df3  y5pfnbmp-1  0.000126\n",
            "2  01b1bf81-d314-4612-97e9-517477823df3  eo2eyhgk-1  0.000126\n",
            "3  01b1bf81-d314-4612-97e9-517477823df3  fknyydal-1  0.000126\n",
            "4  01b1bf81-d314-4612-97e9-517477823df3  61ogen4w-1  0.000126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-Based Location-Aware Recommendations\n",
        "\n",
        "*A lightweight rule-based algorithm leveraging user location and global popularity.*"
      ],
      "metadata": {
        "id": "qOg3YkMmhnmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_content = (\n",
        "    event_df[event_df['event_type'] == 'TimeSpent-Front']\n",
        "    .groupby('hashId')\n",
        "    .size()\n",
        "    .reset_index(name='view_count')\n",
        "    .sort_values('view_count', ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n"
      ],
      "metadata": {
        "id": "FhIs737aVcPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_content.head())  # Should have columns: hashId, view_count (at least)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVhrPB3CVZ00",
        "outputId": "132634f3-4073-42ca-9dc1-87b8f752805c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       hashId  view_count\n",
            "0  q4dqaz8m-1        5391\n",
            "1  im5bxn3a-1        4962\n",
            "2  7q98ag4y-1        4549\n",
            "3  4hvxw5is-1        4523\n",
            "4  b406vqmy-1        4294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  Correct path to device file in Google Drive\n",
        "device_path = '/content/drive/MyDrive/test_data/devices/part-00000-cdb2cdd7-9d14-4000-b947-4d0475444217-c000.csv'\n",
        "\n",
        "#  Loading device data with user locations\n",
        "devices = pd.read_csv(device_path)\n",
        "user_loc = devices[['deviceid', 'lastknownsubadminarea']].dropna().rename(\n",
        "    columns={'deviceid': 'deviceId', 'lastknownsubadminarea': 'location'}\n",
        ")\n",
        "\n",
        "#  Using already available top_content DataFrame\n",
        "# If not available in RAM, load it again:\n",
        "# top_content = pd.read_csv('/content/drive/MyDrive/test_data/top_content.csv')\n",
        "\n",
        "top_pop = top_content.copy()\n",
        "top_pop = top_pop.head(500)  # Ensure it's light enough\n",
        "\n",
        "#  Cartesian join for all location-user pairs and top articles\n",
        "user_loc['key'] = 1\n",
        "top_pop['key'] = 1\n",
        "cand = user_loc.merge(top_pop, on='key').drop(columns='key')\n",
        "\n",
        "#  Ranking articles per user\n",
        "cand['rank'] = cand.groupby('deviceId')['view_count'].rank(ascending=False, method='first')\n",
        "\n",
        "#  Extracting top-50 per user\n",
        "top50_rule = cand[cand['rank'] <= 50][['deviceId', 'hashId', 'rank', 'location']]\n",
        "top50_rule.to_csv('top50_rule_based.csv', index=False)\n",
        "\n",
        "print(\" Rule-based fallback ready:\")\n",
        "print(top50_rule.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9_sBKNBVhIm",
        "outputId": "b127e79b-c20b-4667-cdae-d84dffd309cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Rule-based fallback ready:\n",
            "                               deviceId      hashId  rank location\n",
            "0  8d0972fb-4f2f-4907-9629-188ccda4846a  q4dqaz8m-1   1.0    Noida\n",
            "1  8d0972fb-4f2f-4907-9629-188ccda4846a  im5bxn3a-1   2.0    Noida\n",
            "2  8d0972fb-4f2f-4907-9629-188ccda4846a  7q98ag4y-1   3.0    Noida\n",
            "3  8d0972fb-4f2f-4907-9629-188ccda4846a  4hvxw5is-1   4.0    Noida\n",
            "4  8d0972fb-4f2f-4907-9629-188ccda4846a  b406vqmy-1   5.0    Noida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('submission.csv')\n",
        "files.download('top50_rule_based.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eVg3NKQDfTew",
        "outputId": "1f89d9ed-9c34-4afd-ca21-c664ca74777d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4ecd09a7-bf74-494f-aa8d-5e1e724da973\", \"submission.csv\", 36888722)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5cc88ca3-6a97-4cfc-9228-8dcec76801ef\", \"top50_rule_based.csv\", 29064536)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HbuIDf0Z5Ohl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}